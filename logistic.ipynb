{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d321fbc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:24.413527Z",
     "iopub.status.busy": "2023-12-16T17:39:24.412666Z",
     "iopub.status.idle": "2023-12-16T17:39:24.730736Z",
     "shell.execute_reply": "2023-12-16T17:39:24.729739Z"
    },
    "papermill": {
     "duration": 0.338226,
     "end_time": "2023-12-16T17:39:24.732490",
     "exception": false,
     "start_time": "2023-12-16T17:39:24.394264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ratemeter/sample_submission.csv\n",
      "/kaggle/input/ratemeter/train.csv\n",
      "/kaggle/input/ratemeter/test.csv\n",
      "/kaggle/input/working/pre (1).csv\n",
      "/kaggle/input/pretest/pretest.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba2ab48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:24.764919Z",
     "iopub.status.busy": "2023-12-16T17:39:24.763848Z",
     "iopub.status.idle": "2023-12-16T17:39:42.840918Z",
     "shell.execute_reply": "2023-12-16T17:39:42.840004Z"
    },
    "papermill": {
     "duration": 18.095204,
     "end_time": "2023-12-16T17:39:42.843148",
     "exception": false,
     "start_time": "2023-12-16T17:39:24.747944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/input/ratemeter/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24053e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:42.878456Z",
     "iopub.status.busy": "2023-12-16T17:39:42.877416Z",
     "iopub.status.idle": "2023-12-16T17:39:53.445233Z",
     "shell.execute_reply": "2023-12-16T17:39:53.444142Z"
    },
    "papermill": {
     "duration": 10.588023,
     "end_time": "2023-12-16T17:39:53.447692",
     "exception": false,
     "start_time": "2023-12-16T17:39:42.859669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt=pd.read_csv('/kaggle/input/working/pre (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e11f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:53.480871Z",
     "iopub.status.busy": "2023-12-16T17:39:53.480039Z",
     "iopub.status.idle": "2023-12-16T17:39:53.498025Z",
     "shell.execute_reply": "2023-12-16T17:39:53.497045Z"
    },
    "papermill": {
     "duration": 0.036319,
     "end_time": "2023-12-16T17:39:53.499915",
     "exception": false,
     "start_time": "2023-12-16T17:39:53.463596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finish two day series good stop fuck end</td>\n",
       "      <td>finish two day series good stop fuck end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review follow goodread 4 amazon 5 overall 45</td>\n",
       "      <td>review follow goodread 4 amazon 5 overall 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full review eventually initial hopefully spoil...</td>\n",
       "      <td>full review eventually initial hopefully spoil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 star aww love one read series order even tho...</td>\n",
       "      <td>4 star aww love one read series order even tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>official patrick ness fav author</td>\n",
       "      <td>official patrick ness fav author</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean  \\\n",
       "0           finish two day series good stop fuck end   \n",
       "1       review follow goodread 4 amazon 5 overall 45   \n",
       "2  full review eventually initial hopefully spoil...   \n",
       "3  4 star aww love one read series order even tho...   \n",
       "4                   official patrick ness fav author   \n",
       "\n",
       "                                                 lem  \n",
       "0           finish two day series good stop fuck end  \n",
       "1       review follow goodread 4 amazon 5 overall 45  \n",
       "2  full review eventually initial hopefully spoil...  \n",
       "3  4 star aww love one read series order even tho...  \n",
       "4                   official patrick ness fav author  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7593fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:53.533639Z",
     "iopub.status.busy": "2023-12-16T17:39:53.533129Z",
     "iopub.status.idle": "2023-12-16T17:39:53.537625Z",
     "shell.execute_reply": "2023-12-16T17:39:53.536613Z"
    },
    "papermill": {
     "duration": 0.023042,
     "end_time": "2023-12-16T17:39:53.539313",
     "exception": false,
     "start_time": "2023-12-16T17:39:53.516271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26998503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:53.608134Z",
     "iopub.status.busy": "2023-12-16T17:39:53.607792Z",
     "iopub.status.idle": "2023-12-16T17:39:53.613948Z",
     "shell.execute_reply": "2023-12-16T17:39:53.612965Z"
    },
    "papermill": {
     "duration": 0.024803,
     "end_time": "2023-12-16T17:39:53.615987",
     "exception": false,
     "start_time": "2023-12-16T17:39:53.591184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'book_id', 'review_id', 'review_text', 'date_added',\n",
       "       'date_updated', 'read_at', 'started_at', 'n_votes', 'n_comments',\n",
       "       'rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a569e6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:53.649326Z",
     "iopub.status.busy": "2023-12-16T17:39:53.649022Z",
     "iopub.status.idle": "2023-12-16T17:39:53.673048Z",
     "shell.execute_reply": "2023-12-16T17:39:53.672176Z"
    },
    "papermill": {
     "duration": 0.042761,
     "end_time": "2023-12-16T17:39:53.675258",
     "exception": false,
     "start_time": "2023-12-16T17:39:53.632497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df.drop(columns=['user_id', 'book_id', 'review_id',  'date_added',\n",
    "       'date_updated', 'read_at', 'started_at', 'n_votes', 'n_comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b0f39",
   "metadata": {
    "papermill": {
     "duration": 0.016907,
     "end_time": "2023-12-16T17:39:53.708477",
     "exception": false,
     "start_time": "2023-12-16T17:39:53.691570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c1000d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:39:53.742693Z",
     "iopub.status.busy": "2023-12-16T17:39:53.742380Z",
     "iopub.status.idle": "2023-12-16T17:40:23.157138Z",
     "shell.execute_reply": "2023-12-16T17:40:23.156469Z"
    },
    "papermill": {
     "duration": 29.433438,
     "end_time": "2023-12-16T17:40:23.159040",
     "exception": false,
     "start_time": "2023-12-16T17:39:53.725602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3033788060.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review_text  rating  \\\n",
      "0       I finished this in two days. THIS SERIES IS JU...       5   \n",
      "1       Review to follow \\n Goodreads 4 \\n Amazon 5 \\n...       5   \n",
      "2       I will have a full review up eventually but fo...       5   \n",
      "3       4 stars. Aww! I loved this one! I have read th...       4   \n",
      "4         this is official: Patrick Ness is my fav author       5   \n",
      "...                                                   ...     ...   \n",
      "629995  Wow, just ... wow. I absolutely loved this boo...       5   \n",
      "629996                           ***Review Coming Soon***       3   \n",
      "629997  I'm in love with Marie Rutkoski's writing. It'...       5   \n",
      "629998  It was pretty much a walking contradiction. \\n...       3   \n",
      "629999  Lianne Challice is a princess, OK she is an ac...       4   \n",
      "\n",
      "                                                    clean  \n",
      "0       I finished this in two days. THIS SERIES IS JU...  \n",
      "1       Review to follow \\n Goodreads 4 \\n Amazon 5 \\n...  \n",
      "2       I will have a full review up eventually but fo...  \n",
      "3       4 stars. Aww! I loved this one! I have read th...  \n",
      "4         this is official: Patrick Ness is my fav author  \n",
      "...                                                   ...  \n",
      "629995  Wow, just ... wow. I absolutely loved this boo...  \n",
      "629996                           ***Review Coming Soon***  \n",
      "629997  I'm in love with Marie Rutkoski's writing. It'...  \n",
      "629998  It was pretty much a walking contradiction. \\n...  \n",
      "629999  Lianne Challice is a princess, OK she is an ac...  \n",
      "\n",
      "[630000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Apply the function to the 'review_text' column\n",
    "df['clean'] = df['review_text'].apply(remove_html_tags)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cbf03",
   "metadata": {
    "papermill": {
     "duration": 0.015541,
     "end_time": "2023-12-16T17:40:23.192058",
     "exception": false,
     "start_time": "2023-12-16T17:40:23.176517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae964cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:23.225425Z",
     "iopub.status.busy": "2023-12-16T17:40:23.224381Z",
     "iopub.status.idle": "2023-12-16T17:40:23.228681Z",
     "shell.execute_reply": "2023-12-16T17:40:23.228097Z"
    },
    "papermill": {
     "duration": 0.02259,
     "end_time": "2023-12-16T17:40:23.230380",
     "exception": false,
     "start_time": "2023-12-16T17:40:23.207790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df[:400000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff931d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:23.263696Z",
     "iopub.status.busy": "2023-12-16T17:40:23.263386Z",
     "iopub.status.idle": "2023-12-16T17:40:30.764018Z",
     "shell.execute_reply": "2023-12-16T17:40:30.762954Z"
    },
    "papermill": {
     "duration": 7.520163,
     "end_time": "2023-12-16T17:40:30.767042",
     "exception": false,
     "start_time": "2023-12-16T17:40:23.246879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I finished this in two days. THIS SERIES IS JU...</td>\n",
       "      <td>5</td>\n",
       "      <td>I finished this in two days THIS SERIES IS JUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review to follow \\n Goodreads 4 \\n Amazon 5 \\n...</td>\n",
       "      <td>5</td>\n",
       "      <td>Review to follow \\n Goodreads 4 \\n Amazon 5 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will have a full review up eventually but fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>I will have a full review up eventually but fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 stars. Aww! I loved this one! I have read th...</td>\n",
       "      <td>4</td>\n",
       "      <td>4 stars Aww I loved this one I have read this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is official: Patrick Ness is my fav author</td>\n",
       "      <td>5</td>\n",
       "      <td>this is official Patrick Ness is my fav author</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating  \\\n",
       "0  I finished this in two days. THIS SERIES IS JU...       5   \n",
       "1  Review to follow \\n Goodreads 4 \\n Amazon 5 \\n...       5   \n",
       "2  I will have a full review up eventually but fo...       5   \n",
       "3  4 stars. Aww! I loved this one! I have read th...       4   \n",
       "4    this is official: Patrick Ness is my fav author       5   \n",
       "\n",
       "                                               clean  \n",
       "0  I finished this in two days THIS SERIES IS JUS...  \n",
       "1  Review to follow \\n Goodreads 4 \\n Amazon 5 \\n...  \n",
       "2  I will have a full review up eventually but fo...  \n",
       "3  4 stars Aww I loved this one I have read this ...  \n",
       "4     this is official Patrick Ness is my fav author  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # Use a regular expression to remove non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to the 'review_text' column\n",
    "df['clean'] = df['clean'].apply(remove_special_characters)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19acdf0",
   "metadata": {
    "papermill": {
     "duration": 0.018661,
     "end_time": "2023-12-16T17:40:30.806892",
     "exception": false,
     "start_time": "2023-12-16T17:40:30.788231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e4b8117",
   "metadata": {
    "papermill": {
     "duration": 0.016223,
     "end_time": "2023-12-16T17:40:30.839490",
     "exception": false,
     "start_time": "2023-12-16T17:40:30.823267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making it to lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23b26c",
   "metadata": {
    "papermill": {
     "duration": 0.016897,
     "end_time": "2023-12-16T17:40:30.874800",
     "exception": false,
     "start_time": "2023-12-16T17:40:30.857903",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "992a1ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:30.908512Z",
     "iopub.status.busy": "2023-12-16T17:40:30.907423Z",
     "iopub.status.idle": "2023-12-16T17:40:31.281189Z",
     "shell.execute_reply": "2023-12-16T17:40:31.280272Z"
    },
    "papermill": {
     "duration": 0.3926,
     "end_time": "2023-12-16T17:40:31.283166",
     "exception": false,
     "start_time": "2023-12-16T17:40:30.890566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  rating  \\\n",
      "0  I finished this in two days. THIS SERIES IS JU...       5   \n",
      "1  Review to follow \\n Goodreads 4 \\n Amazon 5 \\n...       5   \n",
      "2  I will have a full review up eventually but fo...       5   \n",
      "3  4 stars. Aww! I loved this one! I have read th...       4   \n",
      "4    this is official: Patrick Ness is my fav author       5   \n",
      "\n",
      "                                               clean  \n",
      "0  i finished this in two days this series is jus...  \n",
      "1  review to follow \\n goodreads 4 \\n amazon 5 \\n...  \n",
      "2  i will have a full review up eventually but fo...  \n",
      "3  4 stars aww i loved this one i have read this ...  \n",
      "4     this is official patrick ness is my fav author  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert 'review_text' column to lowercase\n",
    "df['clean'] = df['clean'].str.lower()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5346e0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:31.318789Z",
     "iopub.status.busy": "2023-12-16T17:40:31.318244Z",
     "iopub.status.idle": "2023-12-16T17:40:31.325070Z",
     "shell.execute_reply": "2023-12-16T17:40:31.324078Z"
    },
    "papermill": {
     "duration": 0.027236,
     "end_time": "2023-12-16T17:40:31.326886",
     "exception": false,
     "start_time": "2023-12-16T17:40:31.299650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    5\n",
       "3    4\n",
       "4    5\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "y=df['rating']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09eabcaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:31.361037Z",
     "iopub.status.busy": "2023-12-16T17:40:31.360529Z",
     "iopub.status.idle": "2023-12-16T17:40:31.383701Z",
     "shell.execute_reply": "2023-12-16T17:40:31.383104Z"
    },
    "papermill": {
     "duration": 0.042673,
     "end_time": "2023-12-16T17:40:31.386088",
     "exception": false,
     "start_time": "2023-12-16T17:40:31.343415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df.drop(columns=['review_text','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bcd310a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:31.422197Z",
     "iopub.status.busy": "2023-12-16T17:40:31.421603Z",
     "iopub.status.idle": "2023-12-16T17:40:31.429987Z",
     "shell.execute_reply": "2023-12-16T17:40:31.428872Z"
    },
    "papermill": {
     "duration": 0.028994,
     "end_time": "2023-12-16T17:40:31.431972",
     "exception": false,
     "start_time": "2023-12-16T17:40:31.402978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i finished this in two days this series is jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review to follow \\n goodreads 4 \\n amazon 5 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will have a full review up eventually but fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 stars aww i loved this one i have read this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is official patrick ness is my fav author</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean\n",
       "0  i finished this in two days this series is jus...\n",
       "1  review to follow \\n goodreads 4 \\n amazon 5 \\n...\n",
       "2  i will have a full review up eventually but fo...\n",
       "3  4 stars aww i loved this one i have read this ...\n",
       "4     this is official patrick ness is my fav author"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e259d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:31.465767Z",
     "iopub.status.busy": "2023-12-16T17:40:31.465461Z",
     "iopub.status.idle": "2023-12-16T17:40:41.527075Z",
     "shell.execute_reply": "2023-12-16T17:40:41.526293Z"
    },
    "papermill": {
     "duration": 10.080374,
     "end_time": "2023-12-16T17:40:41.528826",
     "exception": false,
     "start_time": "2023-12-16T17:40:31.448452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa78c0",
   "metadata": {
    "papermill": {
     "duration": 0.017639,
     "end_time": "2023-12-16T17:40:41.564324",
     "exception": false,
     "start_time": "2023-12-16T17:40:41.546685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a80849f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:40:41.598462Z",
     "iopub.status.busy": "2023-12-16T17:40:41.598111Z",
     "iopub.status.idle": "2023-12-16T17:44:51.291445Z",
     "shell.execute_reply": "2023-12-16T17:44:51.290223Z"
    },
    "papermill": {
     "duration": 249.730126,
     "end_time": "2023-12-16T17:44:51.310905",
     "exception": false,
     "start_time": "2023-12-16T17:40:41.580779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "                                               clean\n",
      "0  [i, finished, this, in, two, days, this, serie...\n",
      "1  [review, to, follow, goodreads, 4, amazon, 5, ...\n",
      "2  [i, will, have, a, full, review, up, eventuall...\n",
      "3  [4, stars, aww, i, loved, this, one, i, have, ...\n",
      "4  [this, is, official, patrick, ness, is, my, fa...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# Download the NLTK punkt dataset for tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Apply the function to the 'clean' column\n",
    "df['clean'] = df['clean'].apply(tokenize_text)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da9dda",
   "metadata": {
    "papermill": {
     "duration": 0.016062,
     "end_time": "2023-12-16T17:44:51.344242",
     "exception": false,
     "start_time": "2023-12-16T17:44:51.328180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7f64b",
   "metadata": {
    "papermill": {
     "duration": 0.016339,
     "end_time": "2023-12-16T17:44:51.377021",
     "exception": false,
     "start_time": "2023-12-16T17:44:51.360682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adc17cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:44:51.411889Z",
     "iopub.status.busy": "2023-12-16T17:44:51.411482Z",
     "iopub.status.idle": "2023-12-16T17:45:49.386575Z",
     "shell.execute_reply": "2023-12-16T17:45:49.385896Z"
    },
    "papermill": {
     "duration": 58.010871,
     "end_time": "2023-12-16T17:45:49.404283",
     "exception": false,
     "start_time": "2023-12-16T17:44:51.393412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "                                               clean\n",
      "0  [finished, two, days, series, good, stop, fuck...\n",
      "1  [review, follow, goodreads, 4, amazon, 5, over...\n",
      "2  [full, review, eventually, initial, hopefully,...\n",
      "3  [4, stars, aww, loved, one, read, series, orde...\n",
      "4             [official, patrick, ness, fav, author]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to remove stopwords from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "# Remove stopwords from the tokenized lists\n",
    "df['clean'] = df['clean'].apply(remove_stopwords)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b53d7c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:45:49.439990Z",
     "iopub.status.busy": "2023-12-16T17:45:49.439317Z",
     "iopub.status.idle": "2023-12-16T17:45:58.908484Z",
     "shell.execute_reply": "2023-12-16T17:45:58.906905Z"
    },
    "papermill": {
     "duration": 9.490027,
     "end_time": "2023-12-16T17:45:58.910433",
     "exception": false,
     "start_time": "2023-12-16T17:45:49.420406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.1)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.3.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.12)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.1.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.24.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.0.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28cc2a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:45:58.946687Z",
     "iopub.status.busy": "2023-12-16T17:45:58.946354Z",
     "iopub.status.idle": "2023-12-16T17:46:13.049039Z",
     "shell.execute_reply": "2023-12-16T17:46:13.047947Z"
    },
    "papermill": {
     "duration": 14.122906,
     "end_time": "2023-12-16T17:46:13.051349",
     "exception": false,
     "start_time": "2023-12-16T17:45:58.928443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.3.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.1.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2c25640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T17:46:13.089618Z",
     "iopub.status.busy": "2023-12-16T17:46:13.089301Z",
     "iopub.status.idle": "2023-12-16T18:29:53.558068Z",
     "shell.execute_reply": "2023-12-16T18:29:53.556851Z"
    },
    "papermill": {
     "duration": 2620.508883,
     "end_time": "2023-12-16T18:29:53.578623",
     "exception": false,
     "start_time": "2023-12-16T17:46:13.069740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               clean\n",
      "0  [finish, two, day, series, good, stop, fuck, end]\n",
      "1  [review, follow, goodread, 4, amazon, 5, overa...\n",
      "2  [full, review, eventually, initial, hopefully,...\n",
      "3  [4, star, aww, love, one, read, series, order,...\n",
      "4             [official, patrick, ness, fav, author]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "# Function to perform lemmatization using spaCy\n",
    "def lemmatize_with_spacy(tokens):\n",
    "    # Join the list of tokens into a string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    # Apply lemmatization using spaCy\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply lemmatization using spaCy to the 'clean' column\n",
    "df['clean'] = df['clean'].apply(lemmatize_with_spacy)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6382d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:29:53.615922Z",
     "iopub.status.busy": "2023-12-16T18:29:53.615264Z",
     "iopub.status.idle": "2023-12-16T18:29:53.695201Z",
     "shell.execute_reply": "2023-12-16T18:29:53.694329Z"
    },
    "papermill": {
     "duration": 0.10106,
     "end_time": "2023-12-16T18:29:53.697120",
     "exception": false,
     "start_time": "2023-12-16T18:29:53.596060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   clean   400000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b2adc3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:29:53.735053Z",
     "iopub.status.busy": "2023-12-16T18:29:53.734473Z",
     "iopub.status.idle": "2023-12-16T18:29:53.744964Z",
     "shell.execute_reply": "2023-12-16T18:29:53.744087Z"
    },
    "papermill": {
     "duration": 0.031412,
     "end_time": "2023-12-16T18:29:53.746667",
     "exception": false,
     "start_time": "2023-12-16T18:29:53.715255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [finish, two, day, series, good, stop, fuck, end]\n",
       "1         [review, follow, goodread, 4, amazon, 5, overa...\n",
       "2         [full, review, eventually, initial, hopefully,...\n",
       "3         [4, star, aww, love, one, read, series, order,...\n",
       "4                    [official, patrick, ness, fav, author]\n",
       "                                ...                        \n",
       "399995    [see, dead, people, wise, crack, snarky, barke...\n",
       "399996    [inexplicably, like, book, hard, review, eloqu...\n",
       "399997    [hope, would, little, funnier, light, actually...\n",
       "399998    [yet, another, 5star, gaiman, book, man, amazi...\n",
       "399999    [edward, leave, god, tell, get, back, pick, fl...\n",
       "Name: clean, Length: 400000, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73070170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:29:53.783540Z",
     "iopub.status.busy": "2023-12-16T18:29:53.782924Z",
     "iopub.status.idle": "2023-12-16T18:29:54.827483Z",
     "shell.execute_reply": "2023-12-16T18:29:54.826222Z"
    },
    "papermill": {
     "duration": 1.06536,
     "end_time": "2023-12-16T18:29:54.829948",
     "exception": false,
     "start_time": "2023-12-16T18:29:53.764588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['lem'] = df['clean'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "744e1b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:29:54.868521Z",
     "iopub.status.busy": "2023-12-16T18:29:54.868206Z",
     "iopub.status.idle": "2023-12-16T18:29:54.875968Z",
     "shell.execute_reply": "2023-12-16T18:29:54.874868Z"
    },
    "papermill": {
     "duration": 0.02964,
     "end_time": "2023-12-16T18:29:54.878299",
     "exception": false,
     "start_time": "2023-12-16T18:29:54.848659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             finish two day series good stop fuck end\n",
       "1         review follow goodread 4 amazon 5 overall 45\n",
       "2    full review eventually initial hopefully spoil...\n",
       "3    4 star aww love one read series order even tho...\n",
       "4                     official patrick ness fav author\n",
       "Name: lem, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lem'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020cac75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:29:54.916951Z",
     "iopub.status.busy": "2023-12-16T18:29:54.916231Z",
     "iopub.status.idle": "2023-12-16T18:29:54.925956Z",
     "shell.execute_reply": "2023-12-16T18:29:54.925221Z"
    },
    "papermill": {
     "duration": 0.030441,
     "end_time": "2023-12-16T18:29:54.927604",
     "exception": false,
     "start_time": "2023-12-16T18:29:54.897163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean']=df['lem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19ba37eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:29:54.964976Z",
     "iopub.status.busy": "2023-12-16T18:29:54.964358Z",
     "iopub.status.idle": "2023-12-16T18:30:02.286640Z",
     "shell.execute_reply": "2023-12-16T18:30:02.285862Z"
    },
    "papermill": {
     "duration": 7.343421,
     "end_time": "2023-12-16T18:30:02.288779",
     "exception": false,
     "start_time": "2023-12-16T18:29:54.945358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('pre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32186eeb",
   "metadata": {
    "papermill": {
     "duration": 0.018548,
     "end_time": "2023-12-16T18:30:02.326171",
     "exception": false,
     "start_time": "2023-12-16T18:30:02.307623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e513611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:02.366007Z",
     "iopub.status.busy": "2023-12-16T18:30:02.365599Z",
     "iopub.status.idle": "2023-12-16T18:30:02.392410Z",
     "shell.execute_reply": "2023-12-16T18:30:02.391386Z"
    },
    "papermill": {
     "duration": 0.049663,
     "end_time": "2023-12-16T18:30:02.394223",
     "exception": false,
     "start_time": "2023-12-16T18:30:02.344560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finish two day series good stop fuck end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review follow goodread 4 amazon 5 overall 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full review eventually initial hopefully spoil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 star aww love one read series order even tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>official patrick ness fav author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>see dead people wise crack snarky barkeeper rh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>inexplicably like book hard review eloquent th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>hope would little funnier light actually still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>yet another 5star gaiman book man amazing abil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>edward leave god tell get back pick floor alre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    clean\n",
       "0                finish two day series good stop fuck end\n",
       "1            review follow goodread 4 amazon 5 overall 45\n",
       "2       full review eventually initial hopefully spoil...\n",
       "3       4 star aww love one read series order even tho...\n",
       "4                        official patrick ness fav author\n",
       "...                                                   ...\n",
       "399995  see dead people wise crack snarky barkeeper rh...\n",
       "399996  inexplicably like book hard review eloquent th...\n",
       "399997  hope would little funnier light actually still...\n",
       "399998  yet another 5star gaiman book man amazing abil...\n",
       "399999  edward leave god tell get back pick floor alre...\n",
       "\n",
       "[400000 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['lem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eec4a62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:02.434766Z",
     "iopub.status.busy": "2023-12-16T18:30:02.433641Z",
     "iopub.status.idle": "2023-12-16T18:30:02.442604Z",
     "shell.execute_reply": "2023-12-16T18:30:02.441869Z"
    },
    "papermill": {
     "duration": 0.030878,
     "end_time": "2023-12-16T18:30:02.444254",
     "exception": false,
     "start_time": "2023-12-16T18:30:02.413376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finish two day series good stop fuck end</td>\n",
       "      <td>finish two day series good stop fuck end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review follow goodread 4 amazon 5 overall 45</td>\n",
       "      <td>review follow goodread 4 amazon 5 overall 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full review eventually initial hopefully spoil...</td>\n",
       "      <td>full review eventually initial hopefully spoil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 star aww love one read series order even tho...</td>\n",
       "      <td>4 star aww love one read series order even tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>official patrick ness fav author</td>\n",
       "      <td>official patrick ness fav author</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean  \\\n",
       "0           finish two day series good stop fuck end   \n",
       "1       review follow goodread 4 amazon 5 overall 45   \n",
       "2  full review eventually initial hopefully spoil...   \n",
       "3  4 star aww love one read series order even tho...   \n",
       "4                   official patrick ness fav author   \n",
       "\n",
       "                                                 lem  \n",
       "0           finish two day series good stop fuck end  \n",
       "1       review follow goodread 4 amazon 5 overall 45  \n",
       "2  full review eventually initial hopefully spoil...  \n",
       "3  4 star aww love one read series order even tho...  \n",
       "4                   official patrick ness fav author  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ae0bc52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:02.483263Z",
     "iopub.status.busy": "2023-12-16T18:30:02.482223Z",
     "iopub.status.idle": "2023-12-16T18:30:02.597337Z",
     "shell.execute_reply": "2023-12-16T18:30:02.596613Z"
    },
    "papermill": {
     "duration": 0.136345,
     "end_time": "2023-12-16T18:30:02.599416",
     "exception": false,
     "start_time": "2023-12-16T18:30:02.463071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt['lem'] = dt['lem'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "155a1bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:02.638430Z",
     "iopub.status.busy": "2023-12-16T18:30:02.637340Z",
     "iopub.status.idle": "2023-12-16T18:30:10.106315Z",
     "shell.execute_reply": "2023-12-16T18:30:10.105274Z"
    },
    "papermill": {
     "duration": 7.49025,
     "end_time": "2023-12-16T18:30:10.108602",
     "exception": false,
     "start_time": "2023-12-16T18:30:02.618352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt.to_csv('actual_pretrain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "560a11c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:10.146667Z",
     "iopub.status.busy": "2023-12-16T18:30:10.146320Z",
     "iopub.status.idle": "2023-12-16T18:30:10.249494Z",
     "shell.execute_reply": "2023-12-16T18:30:10.248516Z"
    },
    "papermill": {
     "duration": 0.124137,
     "end_time": "2023-12-16T18:30:10.251507",
     "exception": false,
     "start_time": "2023-12-16T18:30:10.127370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean    37\n",
       "lem       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac945125",
   "metadata": {
    "papermill": {
     "duration": 0.01828,
     "end_time": "2023-12-16T18:30:10.289052",
     "exception": false,
     "start_time": "2023-12-16T18:30:10.270772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9049e173",
   "metadata": {
    "papermill": {
     "duration": 0.017961,
     "end_time": "2023-12-16T18:30:10.325232",
     "exception": false,
     "start_time": "2023-12-16T18:30:10.307271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f484816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:10.363448Z",
     "iopub.status.busy": "2023-12-16T18:30:10.362837Z",
     "iopub.status.idle": "2023-12-16T18:30:38.251965Z",
     "shell.execute_reply": "2023-12-16T18:30:38.250968Z"
    },
    "papermill": {
     "duration": 27.911066,
     "end_time": "2023-12-16T18:30:38.254360",
     "exception": false,
     "start_time": "2023-12-16T18:30:10.343294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the 'clean_str' column using TF-IDF vectorization\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dt['lem'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b08e39",
   "metadata": {
    "papermill": {
     "duration": 0.020951,
     "end_time": "2023-12-16T18:30:38.294443",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.273492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb121b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:38.331974Z",
     "iopub.status.busy": "2023-12-16T18:30:38.331464Z",
     "iopub.status.idle": "2023-12-16T18:30:38.336580Z",
     "shell.execute_reply": "2023-12-16T18:30:38.335864Z"
    },
    "papermill": {
     "duration": 0.025815,
     "end_time": "2023-12-16T18:30:38.338163",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.312348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 372813)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18041c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:38.375566Z",
     "iopub.status.busy": "2023-12-16T18:30:38.375313Z",
     "iopub.status.idle": "2023-12-16T18:30:38.378844Z",
     "shell.execute_reply": "2023-12-16T18:30:38.378115Z"
    },
    "papermill": {
     "duration": 0.024158,
     "end_time": "2023-12-16T18:30:38.380368",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.356210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = y[:400000]  # Assuming y is a numpy array or a pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b574bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:38.418383Z",
     "iopub.status.busy": "2023-12-16T18:30:38.417778Z",
     "iopub.status.idle": "2023-12-16T18:30:38.423034Z",
     "shell.execute_reply": "2023-12-16T18:30:38.422279Z"
    },
    "papermill": {
     "duration": 0.026168,
     "end_time": "2023-12-16T18:30:38.424668",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.398500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8768c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:38.463323Z",
     "iopub.status.busy": "2023-12-16T18:30:38.462736Z",
     "iopub.status.idle": "2023-12-16T18:30:38.588624Z",
     "shell.execute_reply": "2023-12-16T18:30:38.587678Z"
    },
    "papermill": {
     "duration": 0.147954,
     "end_time": "2023-12-16T18:30:38.590931",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.442977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(tfidf_matrix, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5c0bb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:38.629239Z",
     "iopub.status.busy": "2023-12-16T18:30:38.628769Z",
     "iopub.status.idle": "2023-12-16T18:30:38.635397Z",
     "shell.execute_reply": "2023-12-16T18:30:38.634848Z"
    },
    "papermill": {
     "duration": 0.027356,
     "end_time": "2023-12-16T18:30:38.637016",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.609660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6d75a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:38.675114Z",
     "iopub.status.busy": "2023-12-16T18:30:38.674654Z",
     "iopub.status.idle": "2023-12-16T18:30:38.678393Z",
     "shell.execute_reply": "2023-12-16T18:30:38.677855Z"
    },
    "papermill": {
     "duration": 0.02478,
     "end_time": "2023-12-16T18:30:38.679977",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.655197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61bc14ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:30:38.718075Z",
     "iopub.status.busy": "2023-12-16T18:30:38.717596Z",
     "iopub.status.idle": "2023-12-16T18:36:14.381505Z",
     "shell.execute_reply": "2023-12-16T18:36:14.380584Z"
    },
    "papermill": {
     "duration": 335.703775,
     "end_time": "2023-12-16T18:36:14.402046",
     "exception": false,
     "start_time": "2023-12-16T18:30:38.698271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5227\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.26      0.36      2767\n",
      "           1       0.49      0.27      0.34      2550\n",
      "           2       0.43      0.29      0.34      6500\n",
      "           3       0.47      0.42      0.44     16867\n",
      "           4       0.49      0.60      0.54     27797\n",
      "           5       0.62      0.63      0.62     23519\n",
      "\n",
      "    accuracy                           0.52     80000\n",
      "   macro avg       0.51      0.41      0.44     80000\n",
      "weighted avg       0.52      0.52      0.52     80000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model on the training data\n",
    "logreg_model.fit(train_data, train_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = logreg_model.predict(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfe5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T16:46:44.961036Z",
     "iopub.status.busy": "2023-12-14T16:46:44.960491Z",
     "iopub.status.idle": "2023-12-14T16:46:45.045023Z",
     "shell.execute_reply": "2023-12-14T16:46:45.043641Z",
     "shell.execute_reply.started": "2023-12-14T16:46:44.960993Z"
    },
    "papermill": {
     "duration": 0.018235,
     "end_time": "2023-12-16T18:36:14.439954",
     "exception": false,
     "start_time": "2023-12-16T18:36:14.421719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd8cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T16:47:00.025450Z",
     "iopub.status.busy": "2023-12-14T16:47:00.025031Z",
     "iopub.status.idle": "2023-12-14T16:47:00.040401Z",
     "shell.execute_reply": "2023-12-14T16:47:00.039022Z",
     "shell.execute_reply.started": "2023-12-14T16:47:00.025416Z"
    },
    "papermill": {
     "duration": 0.019175,
     "end_time": "2023-12-16T18:36:14.479099",
     "exception": false,
     "start_time": "2023-12-16T18:36:14.459924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4568d020",
   "metadata": {
    "papermill": {
     "duration": 0.019596,
     "end_time": "2023-12-16T18:36:14.517936",
     "exception": false,
     "start_time": "2023-12-16T18:36:14.498340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PreProcessing Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909c0cb",
   "metadata": {
    "papermill": {
     "duration": 0.018456,
     "end_time": "2023-12-16T18:36:14.555182",
     "exception": false,
     "start_time": "2023-12-16T18:36:14.536726",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84fc6439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:14.594435Z",
     "iopub.status.busy": "2023-12-16T18:36:14.594064Z",
     "iopub.status.idle": "2023-12-16T18:36:22.093435Z",
     "shell.execute_reply": "2023-12-16T18:36:22.092365Z"
    },
    "papermill": {
     "duration": 7.522027,
     "end_time": "2023-12-16T18:36:22.095965",
     "exception": false,
     "start_time": "2023-12-16T18:36:14.573938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d=pd.read_csv('/kaggle/input/ratemeter/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac224408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:22.193656Z",
     "iopub.status.busy": "2023-12-16T18:36:22.193319Z",
     "iopub.status.idle": "2023-12-16T18:36:25.304735Z",
     "shell.execute_reply": "2023-12-16T18:36:25.303758Z"
    },
    "papermill": {
     "duration": 3.133423,
     "end_time": "2023-12-16T18:36:25.307224",
     "exception": false,
     "start_time": "2023-12-16T18:36:22.173801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm=pd.read_csv('/kaggle/input/ratemeter/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "730db39e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:25.346373Z",
     "iopub.status.busy": "2023-12-16T18:36:25.345985Z",
     "iopub.status.idle": "2023-12-16T18:36:25.374895Z",
     "shell.execute_reply": "2023-12-16T18:36:25.373700Z"
    },
    "papermill": {
     "duration": 0.050458,
     "end_time": "2023-12-16T18:36:25.376776",
     "exception": false,
     "start_time": "2023-12-16T18:36:25.326318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d=d.drop(columns=['user_id', 'book_id', 'review_id',  'date_added',\n",
    "       'date_updated', 'read_at', 'started_at', 'n_votes', 'n_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b27dce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:25.416298Z",
     "iopub.status.busy": "2023-12-16T18:36:25.415352Z",
     "iopub.status.idle": "2023-12-16T18:36:37.789349Z",
     "shell.execute_reply": "2023-12-16T18:36:37.788060Z"
    },
    "papermill": {
     "duration": 12.396165,
     "end_time": "2023-12-16T18:36:37.791599",
     "exception": false,
     "start_time": "2023-12-16T18:36:25.395434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3247520511.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review_text  \\\n",
      "0       I'm going to keep this review short, because I...   \n",
      "1       You know, I was really stoked to see this come...   \n",
      "2       This is one of those books where you know you ...   \n",
      "3       The perks of being a wallflower \\n What does a...   \n",
      "4       So, I wrote a review for this when I read it b...   \n",
      "...                                                   ...   \n",
      "269995  I wanted to read Thirteen Reasons Why even bef...   \n",
      "269996  I had never read a Matthew Quick book before t...   \n",
      "269997  I'm not going to enjoy this at all after the f...   \n",
      "269998  At times I found Tella a little annoying and I...   \n",
      "269999  That was so much better than the first book! S...   \n",
      "\n",
      "                                                    clean  \n",
      "0       I'm going to keep this review short, because I...  \n",
      "1       You know, I was really stoked to see this come...  \n",
      "2       This is one of those books where you know you ...  \n",
      "3       The perks of being a wallflower \\n What does a...  \n",
      "4       So, I wrote a review for this when I read it b...  \n",
      "...                                                   ...  \n",
      "269995  I wanted to read Thirteen Reasons Why even bef...  \n",
      "269996  I had never read a Matthew Quick book before t...  \n",
      "269997  I'm not going to enjoy this at all after the f...  \n",
      "269998  At times I found Tella a little annoying and I...  \n",
      "269999  That was so much better than the first book! S...  \n",
      "\n",
      "[270000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Apply the function to the 'review_text' column\n",
    "d['clean'] = d['review_text'].apply(remove_html_tags)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b08fe3ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:37.833197Z",
     "iopub.status.busy": "2023-12-16T18:36:37.832766Z",
     "iopub.status.idle": "2023-12-16T18:36:42.931529Z",
     "shell.execute_reply": "2023-12-16T18:36:42.930101Z"
    },
    "papermill": {
     "duration": 5.121783,
     "end_time": "2023-12-16T18:36:42.933368",
     "exception": false,
     "start_time": "2023-12-16T18:36:37.811585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going to keep this review short, because I...</td>\n",
       "      <td>Im going to keep this review short because I f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You know, I was really stoked to see this come...</td>\n",
       "      <td>You know I was really stoked to see this come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is one of those books where you know you ...</td>\n",
       "      <td>This is one of those books where you know you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The perks of being a wallflower \\n What does a...</td>\n",
       "      <td>The perks of being a wallflower \\n What does a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So, I wrote a review for this when I read it b...</td>\n",
       "      <td>So I wrote a review for this when I read it bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  I'm going to keep this review short, because I...   \n",
       "1  You know, I was really stoked to see this come...   \n",
       "2  This is one of those books where you know you ...   \n",
       "3  The perks of being a wallflower \\n What does a...   \n",
       "4  So, I wrote a review for this when I read it b...   \n",
       "\n",
       "                                               clean  \n",
       "0  Im going to keep this review short because I f...  \n",
       "1  You know I was really stoked to see this come ...  \n",
       "2  This is one of those books where you know you ...  \n",
       "3  The perks of being a wallflower \\n What does a...  \n",
       "4  So I wrote a review for this when I read it bu...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # Use a regular expression to remove non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to the 'review_text' column\n",
    "d['clean'] = d['clean'].apply(remove_special_characters)\n",
    "\n",
    "# Display the DataFrame\n",
    "d.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b5eed94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:42.975212Z",
     "iopub.status.busy": "2023-12-16T18:36:42.974867Z",
     "iopub.status.idle": "2023-12-16T18:36:43.201533Z",
     "shell.execute_reply": "2023-12-16T18:36:43.200380Z"
    },
    "papermill": {
     "duration": 0.249637,
     "end_time": "2023-12-16T18:36:43.203773",
     "exception": false,
     "start_time": "2023-12-16T18:36:42.954136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  \\\n",
      "0  I'm going to keep this review short, because I...   \n",
      "1  You know, I was really stoked to see this come...   \n",
      "2  This is one of those books where you know you ...   \n",
      "3  The perks of being a wallflower \\n What does a...   \n",
      "4  So, I wrote a review for this when I read it b...   \n",
      "\n",
      "                                               clean  \n",
      "0  im going to keep this review short because i f...  \n",
      "1  you know i was really stoked to see this come ...  \n",
      "2  this is one of those books where you know you ...  \n",
      "3  the perks of being a wallflower \\n what does a...  \n",
      "4  so i wrote a review for this when i read it bu...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert 'review_text' column to lowercase\n",
    "d['clean'] = d['clean'].str.lower()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(d.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc9aed5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:43.243356Z",
     "iopub.status.busy": "2023-12-16T18:36:43.243015Z",
     "iopub.status.idle": "2023-12-16T18:36:43.262040Z",
     "shell.execute_reply": "2023-12-16T18:36:43.260785Z"
    },
    "papermill": {
     "duration": 0.040721,
     "end_time": "2023-12-16T18:36:43.264048",
     "exception": false,
     "start_time": "2023-12-16T18:36:43.223327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d=d.drop(columns=['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8826d51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:36:43.304466Z",
     "iopub.status.busy": "2023-12-16T18:36:43.304127Z",
     "iopub.status.idle": "2023-12-16T18:39:28.084463Z",
     "shell.execute_reply": "2023-12-16T18:39:28.083288Z"
    },
    "papermill": {
     "duration": 164.821639,
     "end_time": "2023-12-16T18:39:28.105732",
     "exception": false,
     "start_time": "2023-12-16T18:36:43.284093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "                                               clean\n",
      "0  [im, going, to, keep, this, review, short, bec...\n",
      "1  [you, know, i, was, really, stoked, to, see, t...\n",
      "2  [this, is, one, of, those, books, where, you, ...\n",
      "3  [the, perks, of, being, a, wallflower, what, d...\n",
      "4  [so, i, wrote, a, review, for, this, when, i, ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# Download the NLTK punkt dataset for tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Apply the function to the 'clean' column\n",
    "d['clean'] = d['clean'].apply(tokenize_text)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(d.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3e1ffc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:39:28.147892Z",
     "iopub.status.busy": "2023-12-16T18:39:28.147510Z",
     "iopub.status.idle": "2023-12-16T18:40:08.645315Z",
     "shell.execute_reply": "2023-12-16T18:40:08.643668Z"
    },
    "papermill": {
     "duration": 40.538058,
     "end_time": "2023-12-16T18:40:08.664371",
     "exception": false,
     "start_time": "2023-12-16T18:39:28.126313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "                                               clean  \\\n",
      "0           finish two day series good stop fuck end   \n",
      "1       review follow goodread 4 amazon 5 overall 45   \n",
      "2  full review eventually initial hopefully spoil...   \n",
      "3  4 star aww love one read series order even tho...   \n",
      "4                   official patrick ness fav author   \n",
      "\n",
      "                                                 lem  \n",
      "0           finish two day series good stop fuck end  \n",
      "1       review follow goodread 4 amazon 5 overall 45  \n",
      "2  full review eventually initial hopefully spoil...  \n",
      "3  4 star aww love one read series order even tho...  \n",
      "4                   official patrick ness fav author  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to remove stopwords from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "# Remove stopwords from the tokenized lists\n",
    "d['clean'] = d['clean'].apply(remove_stopwords)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9447361f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T18:40:08.703485Z",
     "iopub.status.busy": "2023-12-16T18:40:08.703107Z",
     "iopub.status.idle": "2023-12-16T19:10:03.037403Z",
     "shell.execute_reply": "2023-12-16T19:10:03.036504Z"
    },
    "papermill": {
     "duration": 1794.3754,
     "end_time": "2023-12-16T19:10:03.058555",
     "exception": false,
     "start_time": "2023-12-16T18:40:08.683155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               clean\n",
      "0  [I, m, go, keep, review, short, feel, like, da...\n",
      "1  [know, really, stoke, see, come, library, webs...\n",
      "2  [one, book, know, want, reread, reading, year,...\n",
      "3  [perk, wallflower, wallflower, mean, question,...\n",
      "4  [write, review, read, accidentally, delete, wh...\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "# Function to perform lemmatization using spaCy\n",
    "def lemmatize_with_spacy(tokens):\n",
    "    # Join the list of tokens into a string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    # Apply lemmatization using spaCy\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply lemmatization using spaCy to the 'clean' column\n",
    "d['clean'] = d['clean'].apply(lemmatize_with_spacy)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9f1bb7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T19:10:03.098231Z",
     "iopub.status.busy": "2023-12-16T19:10:03.097904Z",
     "iopub.status.idle": "2023-12-16T19:10:03.913552Z",
     "shell.execute_reply": "2023-12-16T19:10:03.912538Z"
    },
    "papermill": {
     "duration": 0.837931,
     "end_time": "2023-12-16T19:10:03.915855",
     "exception": false,
     "start_time": "2023-12-16T19:10:03.077924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d['lem'] = d['clean'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522421c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T17:57:30.612239Z",
     "iopub.status.busy": "2023-12-14T17:57:30.611839Z",
     "iopub.status.idle": "2023-12-14T17:57:30.629482Z",
     "shell.execute_reply": "2023-12-14T17:57:30.628052Z",
     "shell.execute_reply.started": "2023-12-14T17:57:30.612209Z"
    },
    "papermill": {
     "duration": 0.018771,
     "end_time": "2023-12-16T19:10:03.954276",
     "exception": false,
     "start_time": "2023-12-16T19:10:03.935505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766553d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T17:56:54.463625Z",
     "iopub.status.busy": "2023-12-14T17:56:54.463212Z",
     "iopub.status.idle": "2023-12-14T17:56:54.538540Z",
     "shell.execute_reply": "2023-12-14T17:56:54.537287Z",
     "shell.execute_reply.started": "2023-12-14T17:56:54.463585Z"
    },
    "papermill": {
     "duration": 0.018727,
     "end_time": "2023-12-16T19:10:03.991944",
     "exception": false,
     "start_time": "2023-12-16T19:10:03.973217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b517c2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T17:57:22.774948Z",
     "iopub.status.busy": "2023-12-14T17:57:22.774474Z",
     "iopub.status.idle": "2023-12-14T17:57:22.829425Z",
     "shell.execute_reply": "2023-12-14T17:57:22.828080Z",
     "shell.execute_reply.started": "2023-12-14T17:57:22.774903Z"
    },
    "papermill": {
     "duration": 0.018963,
     "end_time": "2023-12-16T19:10:04.029712",
     "exception": false,
     "start_time": "2023-12-16T19:10:04.010749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b49d1c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T19:10:04.072116Z",
     "iopub.status.busy": "2023-12-16T19:10:04.071741Z",
     "iopub.status.idle": "2023-12-16T19:10:04.512034Z",
     "shell.execute_reply": "2023-12-16T19:10:04.510792Z"
    },
    "papermill": {
     "duration": 0.463409,
     "end_time": "2023-12-16T19:10:04.513552",
     "exception": true,
     "start_time": "2023-12-16T19:10:04.050143",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtfidf_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraintf.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "tfidf_matrix.to_csv('traintf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1cb2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:09:41.354605Z",
     "iopub.status.busy": "2023-12-14T18:09:41.354152Z",
     "iopub.status.idle": "2023-12-14T18:09:50.446807Z",
     "shell.execute_reply": "2023-12-14T18:09:50.445461Z",
     "shell.execute_reply.started": "2023-12-14T18:09:41.354548Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d.to_csv('pretest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efae65",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2bd869b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Retreiving Pre proccessed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44cd0cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74db0d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:13:47.449672Z",
     "iopub.status.busy": "2023-12-14T18:13:47.449227Z",
     "iopub.status.idle": "2023-12-14T18:13:53.782417Z",
     "shell.execute_reply": "2023-12-14T18:13:53.780729Z",
     "shell.execute_reply.started": "2023-12-14T18:13:47.449635Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl=pd.read_csv('/kaggle/input/pretest/pretest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57130eca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:15:35.427549Z",
     "iopub.status.busy": "2023-12-14T18:15:35.427112Z",
     "iopub.status.idle": "2023-12-14T18:15:35.480818Z",
     "shell.execute_reply": "2023-12-14T18:15:35.479518Z",
     "shell.execute_reply.started": "2023-12-14T18:15:35.427515Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl['lem'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a52e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:14:39.097402Z",
     "iopub.status.busy": "2023-12-14T18:14:39.096924Z",
     "iopub.status.idle": "2023-12-14T18:14:39.180885Z",
     "shell.execute_reply": "2023-12-14T18:14:39.179409Z",
     "shell.execute_reply.started": "2023-12-14T18:14:39.097364Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl['lem']=dl['lem'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd832f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:42:59.827140Z",
     "iopub.status.busy": "2023-12-14T18:42:59.826652Z",
     "iopub.status.idle": "2023-12-14T18:43:18.104978Z",
     "shell.execute_reply": "2023-12-14T18:43:18.103456Z",
     "shell.execute_reply.started": "2023-12-14T18:42:59.827103Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl.to_csv('actual_pretest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660e03c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:10:53.841019Z",
     "iopub.status.busy": "2023-12-14T18:10:53.840423Z",
     "iopub.status.idle": "2023-12-14T18:10:53.857929Z",
     "shell.execute_reply": "2023-12-14T18:10:53.856283Z",
     "shell.execute_reply.started": "2023-12-14T18:10:53.840969Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436e42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:22:22.579272Z",
     "iopub.status.busy": "2023-12-14T18:22:22.578803Z",
     "iopub.status.idle": "2023-12-14T18:22:22.591086Z",
     "shell.execute_reply": "2023-12-14T18:22:22.589393Z",
     "shell.execute_reply.started": "2023-12-14T18:22:22.579234Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b980e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:24:15.811451Z",
     "iopub.status.busy": "2023-12-14T18:24:15.811000Z",
     "iopub.status.idle": "2023-12-14T18:24:15.913899Z",
     "shell.execute_reply": "2023-12-14T18:24:15.912696Z",
     "shell.execute_reply.started": "2023-12-14T18:24:15.811416Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(dt['lem']=='').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6f3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:23:59.935686Z",
     "iopub.status.busy": "2023-12-14T18:23:59.935241Z",
     "iopub.status.idle": "2023-12-14T18:24:00.006238Z",
     "shell.execute_reply": "2023-12-14T18:24:00.004641Z",
     "shell.execute_reply.started": "2023-12-14T18:23:59.935652Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(dl['lem']=='').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3b694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:22:30.176314Z",
     "iopub.status.busy": "2023-12-14T18:22:30.175770Z",
     "iopub.status.idle": "2023-12-14T18:22:30.189763Z",
     "shell.execute_reply": "2023-12-14T18:22:30.188427Z",
     "shell.execute_reply.started": "2023-12-14T18:22:30.176271Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74ae39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:07:00.670366Z",
     "iopub.status.busy": "2023-12-14T18:07:00.669956Z",
     "iopub.status.idle": "2023-12-14T18:07:00.676658Z",
     "shell.execute_reply": "2023-12-14T18:07:00.675428Z",
     "shell.execute_reply.started": "2023-12-14T18:07:00.670336Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(d.shape\n",
    "print(dt.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc33956",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e73d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:33:28.506306Z",
     "iopub.status.busy": "2023-12-14T18:33:28.505898Z",
     "iopub.status.idle": "2023-12-14T18:34:05.131219Z",
     "shell.execute_reply": "2023-12-14T18:34:05.129955Z",
     "shell.execute_reply.started": "2023-12-14T18:33:28.506275Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Fit and transform the 'clean_str' column using TF-IDF vectorization\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(dl['lem'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d1152",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5c2bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:34:11.763440Z",
     "iopub.status.busy": "2023-12-14T18:34:11.762984Z",
     "iopub.status.idle": "2023-12-14T18:34:11.772259Z",
     "shell.execute_reply": "2023-12-14T18:34:11.770931Z",
     "shell.execute_reply.started": "2023-12-14T18:34:11.763406Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dddf38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:16:50.568615Z",
     "iopub.status.busy": "2023-12-14T18:16:50.568165Z",
     "iopub.status.idle": "2023-12-14T18:16:50.576955Z",
     "shell.execute_reply": "2023-12-14T18:16:50.575645Z",
     "shell.execute_reply.started": "2023-12-14T18:16:50.568576Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637fda82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:34:20.559426Z",
     "iopub.status.busy": "2023-12-14T18:34:20.559027Z",
     "iopub.status.idle": "2023-12-14T18:34:20.830422Z",
     "shell.execute_reply": "2023-12-14T18:34:20.829254Z",
     "shell.execute_reply.started": "2023-12-14T18:34:20.559395Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = logreg_model.predict(tfidf_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a13266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T18:37:47.632653Z",
     "iopub.status.busy": "2023-12-14T18:37:47.632204Z",
     "iopub.status.idle": "2023-12-14T18:37:48.608722Z",
     "shell.execute_reply": "2023-12-14T18:37:48.607616Z",
     "shell.execute_reply.started": "2023-12-14T18:37:47.632617Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'review_id': dm.review_id,\n",
    "                      'rating': predictions})\n",
    "output.to_csv('submissionA.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3001e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm['review']"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6953956,
     "sourceId": 63658,
     "sourceType": "competition"
    },
    {
     "datasetId": 4166339,
     "sourceId": 7202337,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4166835,
     "sourceId": 7202986,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5445.762662,
   "end_time": "2023-12-16T19:10:07.662327",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-16T17:39:21.899665",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
